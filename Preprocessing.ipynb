{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ab2ea7",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92830460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99553965",
   "metadata": {},
   "source": [
    "Пропишем требуемые пути и откроем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fdb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "PATH_SALES_DF_TRAIN = cwd + '/data/raw/sales_df_train.csv'\n",
    "PATH_PR_DF = cwd + '/data/raw/pr_df.csv'\n",
    "PATH_ST_DF = cwd + '/data/raw/st_df.csv'\n",
    "\n",
    "PATH_TO_SAVE_HOLIDAYS = cwd + '/data/holidays.csv'\n",
    "\n",
    "PATH_TO_SAVE_TRAIN_DF = cwd + '/data/preprocessing/preproc_df_train.csv'\n",
    "PATH_TO_SAVE_TEST_DF = cwd + '/data/preprocessing/test.csv'\n",
    "PATH_TO_SAVE_TRAIN_TEST_DF = cwd + '/data/preprocessing/train_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1411c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_train = pd.read_csv(PATH_SALES_DF_TRAIN)\n",
    "pr_df = pd.read_csv(PATH_PR_DF)\n",
    "st_df = pd.read_csv(PATH_ST_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3f6b0",
   "metadata": {},
   "source": [
    "Поскольку предсказывать будем только общее количество продаж товара(pr_sales_in_units), то в датасете sales_df_train оставим только столбцы st_id, pr_sku_id (для джойна с другими датасетами), столбец с датой date и целевой признок pr_sales_in_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1e4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_train = sales_df_train[['st_id', 'pr_sales_type_id', 'pr_sku_id', 'date', 'pr_sales_in_units']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6e2e2",
   "metadata": {},
   "source": [
    "## Предообработка данных по продажам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2c552",
   "metadata": {},
   "source": [
    "Создадим функцию, которая почистит данные, восстановит пропуски в датах и заполнит их нулями (решать будем через словрь)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f67e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clear_df(df, df_date):\n",
    "    new_df = df.copy(deep=True)\n",
    "    # оставим в датасете только значения с целевым признаком больше или равных 0\n",
    "    new_df = new_df[new_df['pr_sales_in_units']>=0].reset_index(drop=True)\n",
    "    if new_df.shape[0] > 0:\n",
    "        #сделаем словарь для заполнения пропусков    \n",
    "        list_col = list(new_df.columns)\n",
    "        list_col.remove('pr_sales_in_units')\n",
    "        dict_for_fillna = {k: new_df.loc[0, k] for k in list_col}\n",
    "\n",
    "        # присоединим датасет с датами\n",
    "        new_df = new_df.merge(df_date, on='date', how='right')\n",
    "        \n",
    "        new_df['pr_sales_in_units'] = new_df['pr_sales_in_units'].fillna(0)\n",
    "        new_df = new_df.sort_values('date').reset_index(drop=True)\n",
    "                \n",
    "        # заполним пропуски, отступаем последние 60 дней (большая их часть будет отброшена за счёт пропусков в скользящих средних)\n",
    "        # заполняем только первые 10 значений, чтобы модель не стремилась предсказывать везде 0\n",
    "        for k, v in dict_for_fillna.items():\n",
    "            new_df.loc[60:,k] = new_df.loc[60:,k].fillna(v, limit=10)        \n",
    "                   \n",
    "    else:\n",
    "        new_df = None\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ba8cf",
   "metadata": {},
   "source": [
    "Напишем функцию, которая привёдт дату к нормальному формату и выделит ряд некоторые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99a1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_and_weekday(df):\n",
    "    #приведём дату в нужный формат, укажем новый индекс и день недели\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['weekday'] = df['date'].dt.weekday \n",
    "    df['weekend'] = (df['weekday'] == 5) | (df['weekday'] == 6)\n",
    "    # преобразуем день недели через тригонометрическую функцию    \n",
    "    df['weekday_cos'] =  np.cos((2 * np.pi) / 7 * (df['weekday'] + 1))\n",
    "    # аналогично поступим с неделями\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['week'] =  np.cos((2 * np.pi) / 53 * (df['week'] + 1))\n",
    "    \n",
    "    df.index = df['date']\n",
    "    df = df.drop('date', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a96f1",
   "metadata": {},
   "source": [
    "Создадим функцию которая будет возвращать средню цену в определённый день за какое-то количество предшествующих недель, в дальнейшем будем получать данные за 4 недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ed2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_in_day(df, weekday_column, column, n_week):\n",
    "    list_weekday_column = df[weekday_column].unique()\n",
    "    for day in list_weekday_column: \n",
    "        new_name_mean = f'mean_in_weekday_{n_week}_week'  \n",
    "        df.loc[(df[weekday_column]==day), new_name_mean] = (df[df[weekday_column]==day][column]\n",
    "                                                           .shift(13).shift()\n",
    "                                                           .rolling(n_week)\n",
    "                                                           .mean()) \n",
    "    df = df.drop(weekday_column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3270f42",
   "metadata": {},
   "source": [
    "Создадим функцию для получения скользящих статистик по каждой из группировок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b306aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling(df, column, n_day_list):    \n",
    "    for n_day in n_day_list:\n",
    "        new_name_mean = f'rolling_mean_{n_day}'\n",
    "        new_name_max = f'rolling_max_{n_day}'\n",
    "        new_name_min = f'rolling_min_{n_day}'        \n",
    "        new_name_max_min = f'rolling_max_min_{n_day}'\n",
    "        new_name_ratio = f'rolling_ratio_{n_day}'     \n",
    "        df[new_name_mean] = (df[column]\n",
    "                               .shift(13).shift()\n",
    "                               .rolling(n_day)\n",
    "                               .mean())\n",
    "        df[new_name_max] = (df[column]\n",
    "                               .shift(13).shift()\n",
    "                               .rolling(n_day)\n",
    "                               .max())\n",
    "        df[new_name_min] = (df[column]\n",
    "                               .shift(13).shift()\n",
    "                               .rolling(n_day)\n",
    "                               .min())\n",
    "        df[new_name_max_min] = (df[new_name_max] + df[new_name_min]) / 2\n",
    "        \n",
    "        df.loc[df[new_name_mean]==0, new_name_mean] = 0.001 #защита от деления на 0\n",
    "        df[new_name_ratio] = df[new_name_max_min] / df[new_name_mean]\n",
    "        df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22599696",
   "metadata": {},
   "source": [
    "Создадим функцию для получения лагов в каждой из группировок. Будем добавлять в датасет лаги в от 1 до 14 дней, затем также посчитаем среднее по лагам в 3 дня по смещениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df66527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lag(df, column, n_day_list):\n",
    "    for n_day in n_day_list:\n",
    "        new_name = f'lag_{n_day}'\n",
    "        df[new_name] = (df[column].shift(13).shift(n_day)) \n",
    "                \n",
    "    df['mean_week_lag'] = df[['lag_5', 'lag_6', 'lag_7']].mean(axis=1)\n",
    "    df['ratio_lag_1_to_mean_week_lag'] = df['lag_1'] / df['mean_week_lag']\n",
    "    df['ratio_lag_1_to_mean_week_lag'] = df['ratio_lag_1_to_mean_week_lag'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74987030",
   "metadata": {},
   "source": [
    "Создадим функцию для обработки нового года, пасхи и праздников. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c08979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_ny_e_h(df, list_holidays, before_2days_holidays_list):\n",
    "    #Добавим флаг нового года и пасхи\n",
    "    df['new_year'] = df.index=='2023-01-01'\n",
    "    df['easter'] = df.index=='2023-04-16'\n",
    "    #\n",
    "    df['week_after_new_year'] = (df.index > '2023-01-01') & (df.index <= '2023-01-08')\n",
    "    df['week_after_easter'] = (df.index > '2023-04-16') & (df.index <= '2023-01-23')\n",
    "    # Добавим флаг после нового года и пасхи\n",
    "    df['week_before_new_year'] = (df.index > '2022-12-24') & (df.index < '2023-01-01')\n",
    "    df['week_before_easter'] = (df.index > '2023-04-09') & (df.index <= '2023-04-16')\n",
    "\n",
    "    #Обработаем список праздников\n",
    "    df['holiday'] = df.index.isin(list_holidays)\n",
    "    # получим данные о днях, которые являются двумя днями, предшествующими праздникам\n",
    "    df['before_2days_holidays'] = df.index.isin(before_2days_holidays_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9b367",
   "metadata": {},
   "source": [
    "Создадим список с праздничными днями с учётом переносов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f656dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_holidays = [\n",
    "    '2022-01-01',\n",
    "    '2022-01-02',\n",
    "    '2022-01-03',\n",
    "    '2022-01-04',\n",
    "    '2022-01-05',\n",
    "    '2022-01-06',\n",
    "    '2022-01-07',\n",
    "    '2022-01-08',\n",
    "    '2022-02-23',\n",
    "    '2022-03-08',\n",
    "    '2022-05-01',\n",
    "    '2022-05-09',\n",
    "    '2022-06-12',\n",
    "    '2022-11-04',\n",
    "    '2022-05-03',\n",
    "    '2022-05-10',\n",
    "    '2022-03-07', \n",
    "    '2023-01-01',\n",
    "    '2023-01-02',\n",
    "    '2023-01-03',\n",
    "    '2023-01-04',\n",
    "    '2023-01-05',\n",
    "    '2023-01-06',\n",
    "    '2023-01-07',\n",
    "    '2023-01-08',\n",
    "    '2023-02-23',\n",
    "    '2023-03-08',\n",
    "    '2023-05-01',\n",
    "    '2023-05-09',\n",
    "    '2023-06-12',\n",
    "    '2023-11-04',\n",
    "    '2023-02-24',\n",
    "    '2023-05-08',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b8a8a",
   "metadata": {},
   "source": [
    "Сохраним данный список для дальнейшего использования в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13be8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays = pd.DataFrame({'holidays': list_holidays})\n",
    "df_holidays.to_csv(PATH_TO_SAVE_HOLIDAYS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449d671",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет получать даты за 2 дня до праздников, при этом продолжительные праздники будет считать одним длинным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be80273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_before_2days_holidays(list_holidays, n_day_before=2):\n",
    "    before_2days_holidays = [list_holidays[0]]\n",
    "    for i in range(1, len(list_holidays)):\n",
    "        last_date = datetime.strptime(list_holidays[i - 1], '%Y-%m-%d') \n",
    "        date = datetime.strptime(list_holidays[i], '%Y-%m-%d')\n",
    "        if last_date != date - timedelta(days = 1):\n",
    "            new_list_day_befor = []\n",
    "            for i in range(1, n_day_before + 1):\n",
    "                new_date = date - timedelta(days = i)\n",
    "                new_date = datetime.strftime(new_date, '%Y-%m-%d')\n",
    "                new_list_day_befor.append(new_date)\n",
    "            before_2days_holidays += new_list_day_befor\n",
    "    return before_2days_holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910a31d",
   "metadata": {},
   "source": [
    "Переименуем в таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048d98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_target(df, column):\n",
    "    df = df.rename(columns = {column: 'target'})    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38365cd8",
   "metadata": {},
   "source": [
    "Поскольку данных много и для данных для предсказаний функции извлечения признаков на полном датасете будут работать долго, то создадим функцию для создания словаря датасетов, что значительно увеличит скорость работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea93934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(df, \n",
    "             df_date,\n",
    "            column = 'pr_sales_in_units',\n",
    "            weekday_column = 'weekday',\n",
    "            n_week_for_lag = 4,\n",
    "            n_day_rolling_list = [7, 14, 30],\n",
    "            n_day_lag_list = list(range(1,15)),\n",
    "            list_holidays = []):\n",
    "    #согласно тз оставим только товары без промо\n",
    "    df = df[df['pr_sales_type_id']==0]\n",
    "    df = df.drop('pr_sales_type_id', axis=1)\n",
    "    df['st_sku'] =  df['st_id'] + '_' + df['pr_sku_id']    \n",
    "    dict_df = {}    \n",
    "    before_2days_holidays_list = get_list_before_2days_holidays(list_holidays)\n",
    "    for x in tqdm(df['st_sku'].unique()):\n",
    "        new_df = df.loc[df['st_sku']==x].copy(deep=True).reset_index(drop=True)\n",
    "        new_df = get_clear_df(new_df, df_date)\n",
    "        if not new_df is None:         \n",
    "            new_df = get_date_and_weekday(new_df)  \n",
    "            new_df = get_mean_in_day(new_df, weekday_column, column, n_week_for_lag)\n",
    "            new_df = get_rolling(new_df, column, n_day_rolling_list)\n",
    "            new_df = get_lag(new_df, column, n_day_lag_list)\n",
    "            new_df = get_features_ny_e_h(new_df, list_holidays, before_2days_holidays_list)\n",
    "            new_df = rename_target(new_df, column)            \n",
    "            new_df = new_df.drop('st_sku', axis=1)      \n",
    "            \n",
    "            dict_df[x] = new_df\n",
    "    \n",
    "    return dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66778c79",
   "metadata": {},
   "source": [
    "Напишем функцию, которая на вход будет принимать датасет, преобразовывать вызывать функцию преобразвоания в словарь и получать готовый результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c644a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_ts(df, \n",
    "                        column = 'pr_sales_in_units',\n",
    "                        weekday_column = 'weekday',\n",
    "                        n_week_for_lag = 4,\n",
    "                        n_day_rolling_list = [7, 14, 30],\n",
    "                        n_day_lag_list = list(range(1,15)),\n",
    "                        list_holidays = []):\n",
    "    print('Начата генерация признаков')\n",
    "    df = df.copy(deep = True)       \n",
    "    df_date = pd.DataFrame(data=df['date'].copy(deep=True).unique(), columns=['date'])\n",
    "    dict_df = get_dict(df,\n",
    "                       df_date,\n",
    "                       column = column,\n",
    "                       weekday_column = weekday_column,\n",
    "                       n_week_for_lag = n_week_for_lag,\n",
    "                       n_day_rolling_list = n_day_rolling_list,\n",
    "                       n_day_lag_list = n_day_lag_list,\n",
    "                       list_holidays = list_holidays)\n",
    "       \n",
    "    return pd.concat(dict_df.values(),axis=0).sort_values(['date','st_id', 'pr_sku_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58b7b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начата генерация признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5995/5995 [05:08<00:00, 19.40it/s]\n"
     ]
    }
   ],
   "source": [
    "df_ts = get_features_for_ts(sales_df_train, list_holidays=list_holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d083c9",
   "metadata": {},
   "source": [
    "Выведем предобработанный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c0a34d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_id</th>\n",
       "      <th>pr_sku_id</th>\n",
       "      <th>target</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_in_weekday_4_week</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_max_7</th>\n",
       "      <th>rolling_min_7</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_week_lag</th>\n",
       "      <th>ratio_lag_1_to_mean_week_lag</th>\n",
       "      <th>new_year</th>\n",
       "      <th>easter</th>\n",
       "      <th>week_after_new_year</th>\n",
       "      <th>week_after_easter</th>\n",
       "      <th>week_before_new_year</th>\n",
       "      <th>week_before_easter</th>\n",
       "      <th>holiday</th>\n",
       "      <th>before_2days_holidays</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>00661699f543753ec7e911a64b9fd2f6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>0094042bfeae507dc7f62acc8e5ed03a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>033013f94a18c066e8b3d610bed34bee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>04bbb07b1057b09d04209991f3eadd8f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>0570ab7d07a4f2587f1ad4c4ed77e333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.794854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       st_id  \\\n",
       "date                                           \n",
       "2022-08-01  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-08-01  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-08-01  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-08-01  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-08-01  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "\n",
       "                                   pr_sku_id  target  weekend  weekday_cos  \\\n",
       "date                                                                         \n",
       "2022-08-01  00661699f543753ec7e911a64b9fd2f6     1.0    False      0.62349   \n",
       "2022-08-01  0094042bfeae507dc7f62acc8e5ed03a     4.0    False      0.62349   \n",
       "2022-08-01  033013f94a18c066e8b3d610bed34bee     4.0    False      0.62349   \n",
       "2022-08-01  04bbb07b1057b09d04209991f3eadd8f     0.0    False      0.62349   \n",
       "2022-08-01  0570ab7d07a4f2587f1ad4c4ed77e333     0.0    False      0.62349   \n",
       "\n",
       "                week  mean_in_weekday_4_week  rolling_mean_7  rolling_max_7  \\\n",
       "date                                                                          \n",
       "2022-08-01 -0.794854                     NaN             NaN            NaN   \n",
       "2022-08-01 -0.794854                     NaN             NaN            NaN   \n",
       "2022-08-01 -0.794854                     NaN             NaN            NaN   \n",
       "2022-08-01 -0.794854                     NaN             NaN            NaN   \n",
       "2022-08-01 -0.794854                     NaN             NaN            NaN   \n",
       "\n",
       "            rolling_min_7  ...  mean_week_lag  ratio_lag_1_to_mean_week_lag  \\\n",
       "date                       ...                                                \n",
       "2022-08-01            NaN  ...            NaN                           0.0   \n",
       "2022-08-01            NaN  ...            NaN                           0.0   \n",
       "2022-08-01            NaN  ...            NaN                           0.0   \n",
       "2022-08-01            NaN  ...            NaN                           0.0   \n",
       "2022-08-01            NaN  ...            NaN                           0.0   \n",
       "\n",
       "            new_year  easter  week_after_new_year  week_after_easter  \\\n",
       "date                                                                   \n",
       "2022-08-01     False   False                False              False   \n",
       "2022-08-01     False   False                False              False   \n",
       "2022-08-01     False   False                False              False   \n",
       "2022-08-01     False   False                False              False   \n",
       "2022-08-01     False   False                False              False   \n",
       "\n",
       "            week_before_new_year  week_before_easter  holiday  \\\n",
       "date                                                            \n",
       "2022-08-01                 False               False    False   \n",
       "2022-08-01                 False               False    False   \n",
       "2022-08-01                 False               False    False   \n",
       "2022-08-01                 False               False    False   \n",
       "2022-08-01                 False               False    False   \n",
       "\n",
       "            before_2days_holidays  \n",
       "date                               \n",
       "2022-08-01                  False  \n",
       "2022-08-01                  False  \n",
       "2022-08-01                  False  \n",
       "2022-08-01                  False  \n",
       "2022-08-01                  False  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a840f6b",
   "metadata": {},
   "source": [
    "## Предообработка данных по товарам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69009e59",
   "metadata": {},
   "source": [
    "Согласно EDA нам необходимо сделать метку для отнесения товара к той или иной категории, согласно динамике цен на них добавим такой столбец в датасет pr_df. Создадим соответствующую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac781ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat(df):\n",
    "    df.loc[df['pr_cat_id']=='c559da2ba967eb820766939a658022c8', 'group_cat'] = 'cat_1'\n",
    "    df.loc[df['pr_subcat_id']=='60787c41b04097dfea76addfccd12243', 'group_cat'] = 'cat_2'\n",
    "    df.loc[df['pr_subcat_id']=='ca34f669ae367c87f0e75dcae0f61ee5', 'group_cat'] = 'cat_3'\n",
    "    df.loc[df['pr_cat_id'].isin(['e58cc5ca94270acaceed13bc82dfedf7', \n",
    "                                          'fb2fcd534b0ff3bbed73cc51df620323']), 'group_cat'] = 'cat_4'\n",
    "    df.loc[df['pr_cat_id'].isin(['3de2334a314a7a72721f1f74a6cb4cee', \n",
    "                                          'f3173935ed8ac4bf073c1bcd63171f8a',\n",
    "                                          'b59c67bf196a4758191e42f76670ceba']), 'group_cat'] = 'cat_5'\n",
    "    df.loc[df['pr_cat_id'].isin(['28fc2782ea7ef51c1104ccf7b9bea13d', \n",
    "                                          '9701a1c165dd9420816bfec5edd6c2b1', \n",
    "                                          '5caf41d62364d5b41a893adc1a9dd5d4', \n",
    "                                          '186a157b2992e7daed3677ce8e9fe40f', \n",
    "                                          '2df45244f09369e16ea3f9117ca45157', \n",
    "                                          '6d9c547cf146054a5a720606a7694467', \n",
    "                                          '535ab76633d94208236a2e829ea6d888', \n",
    "                                          'a6ea8471c120fe8cc35a2954c9b9c595']), 'group_cat'] = 'cat_6'\n",
    "    df.loc[df['pr_cat_id']=='f9ab16852d455ce9203da64f4fc7f92d', 'group_cat'] = 'cat_7'\n",
    "    df.loc[df['pr_cat_id'].isin(['b7087c1f4f89e63af8d46f3b20271153', \n",
    "                                          'f93882cbd8fc7fb794c1011d63be6fb6']), 'group_cat'] = 'cat_8'\n",
    "    df.loc[df['pr_cat_id']=='faafda66202d234463057972460c04f5', 'group_cat'] = 'cat_9'\n",
    "    df.loc[df['pr_cat_id']=='fd5c905bcd8c3348ad1b35d7231ee2b1', 'group_cat'] = 'cat_10'\n",
    "    df.loc[df['pr_cat_id']=='c9f95a0a5af052bffce5c89917335f67', 'group_cat'] = 'cat_11'\n",
    "    df['group_cat'] = df['group_cat'].fillna('cat_12')\n",
    "    df['pr_uom_id'] = df['pr_uom_id']==1\n",
    "    df = df.drop(['pr_cat_id', 'pr_subcat_id', 'pr_group_id'], axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4265ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df = get_cat(pr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7f1eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_sku_id</th>\n",
       "      <th>pr_uom_id</th>\n",
       "      <th>group_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd064933250b0bfe4f926b867b0a5ec8</td>\n",
       "      <td>False</td>\n",
       "      <td>cat_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71c9661741caf40a92a32d1cc8206c04</td>\n",
       "      <td>False</td>\n",
       "      <td>cat_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00b72c2f01a1512cbb1d3f33319bac93</td>\n",
       "      <td>False</td>\n",
       "      <td>cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9bc40cd2fe4f188f402bb41548c5e15c</td>\n",
       "      <td>False</td>\n",
       "      <td>cat_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3a74a370c8eb032acb11ad9119242b8f</td>\n",
       "      <td>False</td>\n",
       "      <td>cat_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pr_sku_id  pr_uom_id group_cat\n",
       "0  fd064933250b0bfe4f926b867b0a5ec8      False     cat_3\n",
       "1  71c9661741caf40a92a32d1cc8206c04      False     cat_1\n",
       "2  00b72c2f01a1512cbb1d3f33319bac93      False    cat_12\n",
       "3  9bc40cd2fe4f188f402bb41548c5e15c      False     cat_3\n",
       "4  3a74a370c8eb032acb11ad9119242b8f      False     cat_1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec4a4a",
   "metadata": {},
   "source": [
    "## Предообработка данных по магазинам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6451ca9",
   "metadata": {},
   "source": [
    "Добавим признак среднего количества проданных товаров в магазине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd29daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sale_group(df, sales_df_train):\n",
    "    df_st_mean = (sales_df_train.groupby('st_id')['pr_sales_in_units'].agg('mean')\n",
    "                      .reset_index(drop=False)\n",
    "                      .sort_values(by='pr_sales_in_units'))\n",
    "    df = df.merge(df_st_mean, on ='st_id')\n",
    "    \n",
    "    df['mean_seale'] = np.nan\n",
    "    df.loc[df['pr_sales_in_units'] < 2.5, 'mean_seale'] = 'mean_seale_1'\n",
    "    df.loc[(df['pr_sales_in_units'] >= 2.5) & (df['pr_sales_in_units'] < 4), 'mean_seale'] = 'mean_seale_2'\n",
    "    df.loc[(df['pr_sales_in_units'] >= 4) & (df['pr_sales_in_units'] < 5), 'mean_seale'] = 'mean_seale_3'\n",
    "    df.loc[(df['pr_sales_in_units'] >= 5), 'mean_seale'] = 'mean_seale_4'\n",
    "  \n",
    "    df = df.drop('pr_sales_in_units', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d60e0",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет высчитывать долю товаров, продаваемых по акции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "071e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio_promo(df, sales_df_train):\n",
    "    df_st_ratio_promo = (sales_df_train.groupby(['st_id', 'pr_sales_type_id'])['pr_sales_in_units']\n",
    "                                .agg('sum')\n",
    "                                .reset_index(drop=False))\n",
    "    df_st_ratio_promo = (df_st_ratio_promo.pivot(columns = 'pr_sales_type_id', index = 'st_id', values = 'pr_sales_in_units')\n",
    "                            .reset_index(drop=False))\n",
    "\n",
    "    df_st_ratio_promo['ratio_promo'] = df_st_ratio_promo[1] / df_st_ratio_promo[0]\n",
    "\n",
    "    df = df.merge(df_st_ratio_promo[['st_id', 'ratio_promo']], on ='st_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d465f94",
   "metadata": {},
   "source": [
    "Воспользуемся функциями написанной в EDA для получения скользящего среднего по всем ТЦ в датасете и рассчёта отношения летних продаж к зимним, чтобы можно было их разбить по группам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d75eb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_ts_store(df, store_columns):\n",
    "    df_st_id = df.groupby(['date',store_columns])['pr_sales_in_units'].agg('sum').reset_index(drop=False)\n",
    "    df_st_id.index = df_st_id['date']\n",
    "    df_st_id = df_st_id.drop('date', axis=1)\n",
    "    return df_st_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6de28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_mean(df, group_column, column):\n",
    "    list_group_column = df[group_column].unique()\n",
    "    for gr_col in list_group_column:\n",
    "        new_name = f'rolling_mean_{column}'\n",
    "        df.loc[df[group_column]==gr_col, new_name] = (df[df[group_column]==gr_col][column]\n",
    "                                                                    .shift(13).shift()\n",
    "                                                                    .rolling(30)\n",
    "                                                                    .mean())\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b8df986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio_summer_winter(df):\n",
    "    df_july = df.loc['2023-07-01'][['st_id', 'rolling_mean_pr_sales_in_units']]\n",
    "    df_jan = df.loc['2023-01-01'][['st_id', 'rolling_mean_pr_sales_in_units']]\n",
    "    new_df = df_july.merge(df_jan, on='st_id', how='left')\n",
    "    new_df.loc[new_df['rolling_mean_pr_sales_in_units_y']==0, 'rolling_mean_pr_sales_in_units_y'] =0.01 #защита от деления на 0\n",
    "    new_df['ratio_summer_winter'] = (new_df['rolling_mean_pr_sales_in_units_x']\n",
    "                                     / new_df['rolling_mean_pr_sales_in_units_y'])\n",
    "    return new_df[['st_id', 'ratio_summer_winter']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e1229",
   "metadata": {},
   "source": [
    "Напишем функцию проводящую полную обработку датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "239d9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_df(df, sales_df_train):\n",
    "    # Оставим только активные магазины и удалим столбец st_is_active\n",
    "    df = df.copy(deep=True)\n",
    "    df = df[df['st_is_active']!=0]\n",
    "    df = df.drop('st_is_active', axis=1)  \n",
    "    \n",
    "    df = get_mean_sale_group(df, sales_df_train)\n",
    "    df = get_ratio_promo(df, sales_df_train)\n",
    "    df_st_id = get_df_ts_store(sales_df_train, 'st_id')\n",
    "    df_st_id = get_rolling_mean(df_st_id, 'st_id', 'pr_sales_in_units')\n",
    "    \n",
    "    df_st_id_1 = df_st_id.groupby('st_id')['rolling_mean_pr_sales_in_units'].agg('max').reset_index(drop=False)\n",
    "    df_st_id_2 = get_ratio_summer_winter(df_st_id)\n",
    "    df_st_id = df_st_id_1.merge(df_st_id_2, on='st_id', how='left')\n",
    "    \n",
    "    df_st_id.loc[df_st_id['rolling_mean_pr_sales_in_units']<500,'group_shop'] = 'group_1'\n",
    "    df_st_id.loc[df_st_id['ratio_summer_winter']>1,'group_shop'] = 'group_2'\n",
    "    df_st_id['group_shop'] = df_st_id['group_shop'].fillna('group_3')\n",
    "    df_st_id = df_st_id.drop(['rolling_mean_pr_sales_in_units', 'ratio_summer_winter'], axis=1)      \n",
    "    \n",
    "    df = df.merge(df_st_id, on ='st_id')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3975f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = get_st_df(st_df, sales_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c6f14",
   "metadata": {},
   "source": [
    "Выведем получившийся датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6b960",
   "metadata": {},
   "source": [
    "## Создание финального датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda572f",
   "metadata": {},
   "source": [
    "Напишем функцию для объединения датасетов магазинов и покупок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb914e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_shops_sales(st_df, df_ts, pr_df):\n",
    "    #объединим получившиеся датасеты, перезададим индексы и удалим пропуски в отсутсвующих торговых центрах\n",
    "    df_ts['date'] = df_ts.index\n",
    "    df = df_ts.merge(st_df, on ='st_id', how='left')\n",
    "    df = df.merge(pr_df, on ='pr_sku_id', how='left')\n",
    "    df.index = df['date']\n",
    "    df = df.drop('date', axis=1)\n",
    "    # Создадим столбец с уникальным сочитанием группы магазина и группы категории товра \n",
    "    # удалим ненужные столбцы и пропуски в данных\n",
    "    df['group_shop_cat'] = df['group_shop'] + '_' + df['group_cat']\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['group_shop', 'group_cat'], axis=1)\n",
    "    \n",
    "      # преобразуем формат столбцов \n",
    "    df['st_type_format_id'] = df['st_type_format_id'].astype('int')\n",
    "    df['st_type_loc_id'] = df['st_type_loc_id'].astype('int')    \n",
    "    df['st_type_size_id'] = df['st_type_size_id'].astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7371a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = combine_shops_sales(st_df, df_ts, pr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ec5547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_id</th>\n",
       "      <th>pr_sku_id</th>\n",
       "      <th>target</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_in_weekday_4_week</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_max_7</th>\n",
       "      <th>rolling_min_7</th>\n",
       "      <th>...</th>\n",
       "      <th>before_2days_holidays</th>\n",
       "      <th>st_city_id</th>\n",
       "      <th>st_division_code</th>\n",
       "      <th>st_type_format_id</th>\n",
       "      <th>st_type_loc_id</th>\n",
       "      <th>st_type_size_id</th>\n",
       "      <th>mean_seale</th>\n",
       "      <th>ratio_promo</th>\n",
       "      <th>pr_uom_id</th>\n",
       "      <th>group_shop_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>01e4734745e97e52d3213449e1a05dd7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>c1f75cc0f7fe269dd0fd9bd5e24f9586</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>mean_seale_4</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>False</td>\n",
       "      <td>group_2_cat_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>02713435f3587e2c81d8f6a9016763ea</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>c1f75cc0f7fe269dd0fd9bd5e24f9586</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>mean_seale_4</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>040a02c2ad1561cbcfc9cae5b4c4b73b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>c1f75cc0f7fe269dd0fd9bd5e24f9586</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>mean_seale_4</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>0448c8afc036bb44c457d7e9edd74c50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>c1f75cc0f7fe269dd0fd9bd5e24f9586</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>mean_seale_4</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>16a5cdae362b8d27a1d8f8c7b78b4330</td>\n",
       "      <td>04bbb07b1057b09d04209991f3eadd8f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.889657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>c1f75cc0f7fe269dd0fd9bd5e24f9586</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>mean_seale_4</td>\n",
       "      <td>0.704237</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       st_id  \\\n",
       "date                                           \n",
       "2022-11-28  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-11-28  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-11-28  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-11-28  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "2022-11-28  16a5cdae362b8d27a1d8f8c7b78b4330   \n",
       "\n",
       "                                   pr_sku_id  target  weekend  weekday_cos  \\\n",
       "date                                                                         \n",
       "2022-11-28  01e4734745e97e52d3213449e1a05dd7     3.0    False      0.62349   \n",
       "2022-11-28  02713435f3587e2c81d8f6a9016763ea     1.0    False      0.62349   \n",
       "2022-11-28  040a02c2ad1561cbcfc9cae5b4c4b73b     1.0    False      0.62349   \n",
       "2022-11-28  0448c8afc036bb44c457d7e9edd74c50     1.0    False      0.62349   \n",
       "2022-11-28  04bbb07b1057b09d04209991f3eadd8f     0.0    False      0.62349   \n",
       "\n",
       "                week  mean_in_weekday_4_week  rolling_mean_7  rolling_max_7  \\\n",
       "date                                                                          \n",
       "2022-11-28  0.889657                     3.0        3.571429            7.0   \n",
       "2022-11-28  0.889657                     0.0        0.001000            0.0   \n",
       "2022-11-28  0.889657                     0.0        0.285714            1.0   \n",
       "2022-11-28  0.889657                     0.0        0.285714            1.0   \n",
       "2022-11-28  0.889657                     0.0        0.142857            1.0   \n",
       "\n",
       "            rolling_min_7  ...  before_2days_holidays  \\\n",
       "date                       ...                          \n",
       "2022-11-28            1.0  ...                  False   \n",
       "2022-11-28            0.0  ...                  False   \n",
       "2022-11-28            0.0  ...                  False   \n",
       "2022-11-28            0.0  ...                  False   \n",
       "2022-11-28            0.0  ...                  False   \n",
       "\n",
       "                                  st_city_id  \\\n",
       "date                                           \n",
       "2022-11-28  c1f75cc0f7fe269dd0fd9bd5e24f9586   \n",
       "2022-11-28  c1f75cc0f7fe269dd0fd9bd5e24f9586   \n",
       "2022-11-28  c1f75cc0f7fe269dd0fd9bd5e24f9586   \n",
       "2022-11-28  c1f75cc0f7fe269dd0fd9bd5e24f9586   \n",
       "2022-11-28  c1f75cc0f7fe269dd0fd9bd5e24f9586   \n",
       "\n",
       "                            st_division_code  st_type_format_id  \\\n",
       "date                                                              \n",
       "2022-11-28  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2022-11-28  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2022-11-28  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2022-11-28  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2022-11-28  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "\n",
       "            st_type_loc_id  st_type_size_id    mean_seale  ratio_promo  \\\n",
       "date                                                                     \n",
       "2022-11-28               2                8  mean_seale_4     0.704237   \n",
       "2022-11-28               2                8  mean_seale_4     0.704237   \n",
       "2022-11-28               2                8  mean_seale_4     0.704237   \n",
       "2022-11-28               2                8  mean_seale_4     0.704237   \n",
       "2022-11-28               2                8  mean_seale_4     0.704237   \n",
       "\n",
       "            pr_uom_id  group_shop_cat  \n",
       "date                                   \n",
       "2022-11-28      False   group_2_cat_5  \n",
       "2022-11-28       True  group_2_cat_12  \n",
       "2022-11-28       True   group_2_cat_6  \n",
       "2022-11-28       True  group_2_cat_12  \n",
       "2022-11-28       True  group_2_cat_12  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a0e2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(PATH_TO_SAVE_TRAIN_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e328e",
   "metadata": {},
   "source": [
    "## Создание объединённой функции препроцессинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cf2b1",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет обрезать датасет по тестовому диапазону, либо генерировать заготовку для прогноза по последней дате датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "814dba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_df(df, first_date = None):\n",
    "    # Если дата среза неизвестна, тогда берём последнюю дату в датасете\n",
    "    if first_date is None:\n",
    "        first_date = df['date'].max()\n",
    "        \n",
    "    unique_st_pr = df[df['pr_sales_type_id']==0].copy(deep=True)\n",
    "    unique_st_pr = unique_st_pr[['st_id', 'pr_sku_id', 'pr_sales_type_id']].drop_duplicates()\n",
    "    \n",
    "    # получим заготовку для предсказаний (будем её делать с завтрашнего дня, поэтому диапазон от 1 до 15)\n",
    "    df_list = [] \n",
    "    for i in range(1, 15):\n",
    "        date = datetime.strptime(first_date, '%Y-%m-%d') + timedelta(days = i)\n",
    "        date = datetime.strftime(date, '%Y-%m-%d')\n",
    "        new_df = unique_st_pr.copy(deep=True)\n",
    "        new_df['pr_sales_in_units'] = 0\n",
    "        new_df['date'] = date\n",
    "        df_list.append(new_df)\n",
    "    new_df = pd.concat(df_list, axis=0)\n",
    "    \n",
    "    #добавим информацию по предыдущему периоду     \n",
    "    old_df = df[['st_id', 'pr_sales_type_id', 'pr_sku_id', 'date', 'pr_sales_in_units']]\n",
    "    \n",
    "    return pd.concat([old_df, new_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a43ca7",
   "metadata": {},
   "source": [
    "Создадим объединённую функцию, которая на вход будет принимать сырые данные по продажам, обработанные данные по категориям товаров для ML модели, обработанные данные по торговым центрам и возвращать обработанный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61eb704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproceccing_df(df, \n",
    "                     pr_df, \n",
    "                     st_df, \n",
    "                     first_date = None,\n",
    "                     is_train = True, \n",
    "                     column = 'pr_sales_in_units',\n",
    "                     weekday_column = 'weekday',\n",
    "                     n_week_for_lag = 4,\n",
    "                     n_day_rolling_list = [7, 14, 30],\n",
    "                     n_day_lag_list = list(range(1,15)),\n",
    "                     list_holidays = []):\n",
    "    pr_df = get_cat(pr_df)\n",
    "    st_df = get_st_df(st_df, df)  \n",
    "    \n",
    "    if first_date is not None:\n",
    "        #если указана первая дата перед прогнозом, то обрезаем датасет\n",
    "        df = df.copy(deep=True)\n",
    "        df.index = pd.to_datetime(df['date'])        \n",
    "        df = df.sort_index()\n",
    "        df = df.loc[:first_date]\n",
    "            \n",
    "    if first_date is None:\n",
    "        # eсли дата среза неизвестна, тогда берём последнюю дату в датасете\n",
    "        first_date = df['date'].max()  \n",
    "        \n",
    "    if not is_train:\n",
    "        #если не тренировочный, то получаем данные через функцию\n",
    "        df = get_test_df(df, first_date = first_date)\n",
    "    \n",
    "    df = df[['st_id', 'pr_sales_type_id', 'pr_sku_id', 'date', 'pr_sales_in_units']]\n",
    "    df = get_features_for_ts(df, \n",
    "                             column = column,\n",
    "                             weekday_column = weekday_column,\n",
    "                             n_week_for_lag = n_week_for_lag,\n",
    "                             n_day_rolling_list = n_day_rolling_list,\n",
    "                             n_day_lag_list = n_day_lag_list,\n",
    "                             list_holidays = list_holidays)\n",
    "    if not is_train:\n",
    "        first_date = datetime.strptime(first_date, '%Y-%m-%d') + timedelta(days = 1)\n",
    "        first_date = datetime.strftime(first_date, '%Y-%m-%d')\n",
    "        df = df.loc[first_date:]\n",
    "    df = combine_shops_sales(st_df, df, pr_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4dea3",
   "metadata": {},
   "source": [
    "Протестируем её работу на данных для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2afaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_train = pd.read_csv(PATH_SALES_DF_TRAIN)\n",
    "pr_df = pd.read_csv(PATH_PR_DF)\n",
    "st_df = pd.read_csv(PATH_ST_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911acf3",
   "metadata": {},
   "source": [
    "Для тестового набора найдм дату среза (сделаем 14 дней для прогноза + 1 день, чтобе получить предшествующую дату)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a615388",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = sales_df_train['date'].max()\n",
    "first_date = datetime.strptime(date, '%Y-%m-%d') - timedelta(days = 15)\n",
    "first_date = datetime.strftime(first_date, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32073810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начата генерация признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5881/5881 [05:30<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 35s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = preproceccing_df(sales_df_train, \n",
    "                           pr_df, \n",
    "                           st_df,\n",
    "                           first_date,\n",
    "                           list_holidays = list_holidays, \n",
    "                           is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c9fc619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начата генерация признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5881/5881 [05:02<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 3s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train_test = preproceccing_df(sales_df_train, \n",
    "                               pr_df, \n",
    "                               st_df,\n",
    "                               first_date,\n",
    "                               list_holidays = list_holidays, \n",
    "                               is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "875f16e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_id</th>\n",
       "      <th>pr_sku_id</th>\n",
       "      <th>target</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_in_weekday_4_week</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_max_7</th>\n",
       "      <th>rolling_min_7</th>\n",
       "      <th>...</th>\n",
       "      <th>before_2days_holidays</th>\n",
       "      <th>st_city_id</th>\n",
       "      <th>st_division_code</th>\n",
       "      <th>st_type_format_id</th>\n",
       "      <th>st_type_loc_id</th>\n",
       "      <th>st_type_size_id</th>\n",
       "      <th>mean_seale</th>\n",
       "      <th>ratio_promo</th>\n",
       "      <th>pr_uom_id</th>\n",
       "      <th>group_shop_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>084a8a9aa8cced9175bd07bc44998e75</td>\n",
       "      <td>0376a60d9a7ce7965beddc4815588697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3202111cf90e7c816a472aaceb72b0df</td>\n",
       "      <td>32586311f16876abf92901085bd87b99</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>mean_seale_1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>group_3_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>084a8a9aa8cced9175bd07bc44998e75</td>\n",
       "      <td>88feeeb024d3f69da7322d76b7b53744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3202111cf90e7c816a472aaceb72b0df</td>\n",
       "      <td>32586311f16876abf92901085bd87b99</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>mean_seale_1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>group_3_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>084a8a9aa8cced9175bd07bc44998e75</td>\n",
       "      <td>be8d2843456cac871fc116ab25d02994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3202111cf90e7c816a472aaceb72b0df</td>\n",
       "      <td>32586311f16876abf92901085bd87b99</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>mean_seale_1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>group_3_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>084a8a9aa8cced9175bd07bc44998e75</td>\n",
       "      <td>c2718cfd2edcbadfe0162a4f4c91f3a0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3202111cf90e7c816a472aaceb72b0df</td>\n",
       "      <td>32586311f16876abf92901085bd87b99</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>mean_seale_1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>group_3_cat_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>084a8a9aa8cced9175bd07bc44998e75</td>\n",
       "      <td>c4a665596d4f67cecb7542c9fad407ee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3202111cf90e7c816a472aaceb72b0df</td>\n",
       "      <td>32586311f16876abf92901085bd87b99</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>mean_seale_1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>group_3_cat_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       st_id  \\\n",
       "date                                           \n",
       "2023-07-04  084a8a9aa8cced9175bd07bc44998e75   \n",
       "2023-07-04  084a8a9aa8cced9175bd07bc44998e75   \n",
       "2023-07-04  084a8a9aa8cced9175bd07bc44998e75   \n",
       "2023-07-04  084a8a9aa8cced9175bd07bc44998e75   \n",
       "2023-07-04  084a8a9aa8cced9175bd07bc44998e75   \n",
       "\n",
       "                                   pr_sku_id  target  weekend  weekday_cos  \\\n",
       "date                                                                         \n",
       "2023-07-04  0376a60d9a7ce7965beddc4815588697     0.0    False    -0.222521   \n",
       "2023-07-04  88feeeb024d3f69da7322d76b7b53744     0.0    False    -0.222521   \n",
       "2023-07-04  be8d2843456cac871fc116ab25d02994     0.0    False    -0.222521   \n",
       "2023-07-04  c2718cfd2edcbadfe0162a4f4c91f3a0     0.0    False    -0.222521   \n",
       "2023-07-04  c4a665596d4f67cecb7542c9fad407ee     0.0    False    -0.222521   \n",
       "\n",
       "                week  mean_in_weekday_4_week  rolling_mean_7  rolling_max_7  \\\n",
       "date                                                                          \n",
       "2023-07-04 -0.984231                     0.0        0.142857            1.0   \n",
       "2023-07-04 -0.984231                     0.0        0.001000            0.0   \n",
       "2023-07-04 -0.984231                     0.0        0.001000            0.0   \n",
       "2023-07-04 -0.984231                     0.0        0.001000            0.0   \n",
       "2023-07-04 -0.984231                     0.0        0.001000            0.0   \n",
       "\n",
       "            rolling_min_7  ...  before_2days_holidays  \\\n",
       "date                       ...                          \n",
       "2023-07-04            0.0  ...                  False   \n",
       "2023-07-04            0.0  ...                  False   \n",
       "2023-07-04            0.0  ...                  False   \n",
       "2023-07-04            0.0  ...                  False   \n",
       "2023-07-04            0.0  ...                  False   \n",
       "\n",
       "                                  st_city_id  \\\n",
       "date                                           \n",
       "2023-07-04  3202111cf90e7c816a472aaceb72b0df   \n",
       "2023-07-04  3202111cf90e7c816a472aaceb72b0df   \n",
       "2023-07-04  3202111cf90e7c816a472aaceb72b0df   \n",
       "2023-07-04  3202111cf90e7c816a472aaceb72b0df   \n",
       "2023-07-04  3202111cf90e7c816a472aaceb72b0df   \n",
       "\n",
       "                            st_division_code  st_type_format_id  \\\n",
       "date                                                              \n",
       "2023-07-04  32586311f16876abf92901085bd87b99                  4   \n",
       "2023-07-04  32586311f16876abf92901085bd87b99                  4   \n",
       "2023-07-04  32586311f16876abf92901085bd87b99                  4   \n",
       "2023-07-04  32586311f16876abf92901085bd87b99                  4   \n",
       "2023-07-04  32586311f16876abf92901085bd87b99                  4   \n",
       "\n",
       "            st_type_loc_id  st_type_size_id    mean_seale  ratio_promo  \\\n",
       "date                                                                     \n",
       "2023-07-04               3               19  mean_seale_1     1.333333   \n",
       "2023-07-04               3               19  mean_seale_1     1.333333   \n",
       "2023-07-04               3               19  mean_seale_1     1.333333   \n",
       "2023-07-04               3               19  mean_seale_1     1.333333   \n",
       "2023-07-04               3               19  mean_seale_1     1.333333   \n",
       "\n",
       "            pr_uom_id  group_shop_cat  \n",
       "date                                   \n",
       "2023-07-04      False  group_3_cat_12  \n",
       "2023-07-04      False  group_3_cat_12  \n",
       "2023-07-04      False  group_3_cat_12  \n",
       "2023-07-04      False  group_3_cat_12  \n",
       "2023-07-04       True   group_3_cat_4  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0148005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_id</th>\n",
       "      <th>pr_sku_id</th>\n",
       "      <th>target</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekday_cos</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_in_weekday_4_week</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_max_7</th>\n",
       "      <th>rolling_min_7</th>\n",
       "      <th>...</th>\n",
       "      <th>before_2days_holidays</th>\n",
       "      <th>st_city_id</th>\n",
       "      <th>st_division_code</th>\n",
       "      <th>st_type_format_id</th>\n",
       "      <th>st_type_loc_id</th>\n",
       "      <th>st_type_size_id</th>\n",
       "      <th>mean_seale</th>\n",
       "      <th>ratio_promo</th>\n",
       "      <th>pr_uom_id</th>\n",
       "      <th>group_shop_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>fa7cdfad1a5aaf8370ebeda47a1ff1c3</td>\n",
       "      <td>fa99a6fd2d3d7419c20fdd03704c5822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>885fe656777008c335ac96072a45be15</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>mean_seale_3</td>\n",
       "      <td>0.762251</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>fa7cdfad1a5aaf8370ebeda47a1ff1c3</td>\n",
       "      <td>fafbee588d44b4a8d561d81680174dc0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>885fe656777008c335ac96072a45be15</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>mean_seale_3</td>\n",
       "      <td>0.762251</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>fa7cdfad1a5aaf8370ebeda47a1ff1c3</td>\n",
       "      <td>fbf6c91454d7c3cea7b03f3092cbfb73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>885fe656777008c335ac96072a45be15</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>mean_seale_3</td>\n",
       "      <td>0.762251</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>fa7cdfad1a5aaf8370ebeda47a1ff1c3</td>\n",
       "      <td>fe50ae64d08d4f8245aaabc55d1baf79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>885fe656777008c335ac96072a45be15</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>mean_seale_3</td>\n",
       "      <td>0.762251</td>\n",
       "      <td>True</td>\n",
       "      <td>group_2_cat_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>fa7cdfad1a5aaf8370ebeda47a1ff1c3</td>\n",
       "      <td>fe5d18ae6650335830e4c1dbd9e6ddb9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.984231</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>885fe656777008c335ac96072a45be15</td>\n",
       "      <td>296bd0cc6e735f9d7488ebc8fbc19130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>mean_seale_3</td>\n",
       "      <td>0.762251</td>\n",
       "      <td>False</td>\n",
       "      <td>group_2_cat_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       st_id  \\\n",
       "date                                           \n",
       "2023-07-03  fa7cdfad1a5aaf8370ebeda47a1ff1c3   \n",
       "2023-07-03  fa7cdfad1a5aaf8370ebeda47a1ff1c3   \n",
       "2023-07-03  fa7cdfad1a5aaf8370ebeda47a1ff1c3   \n",
       "2023-07-03  fa7cdfad1a5aaf8370ebeda47a1ff1c3   \n",
       "2023-07-03  fa7cdfad1a5aaf8370ebeda47a1ff1c3   \n",
       "\n",
       "                                   pr_sku_id  target  weekend  weekday_cos  \\\n",
       "date                                                                         \n",
       "2023-07-03  fa99a6fd2d3d7419c20fdd03704c5822     0.0    False      0.62349   \n",
       "2023-07-03  fafbee588d44b4a8d561d81680174dc0     0.0    False      0.62349   \n",
       "2023-07-03  fbf6c91454d7c3cea7b03f3092cbfb73     2.0    False      0.62349   \n",
       "2023-07-03  fe50ae64d08d4f8245aaabc55d1baf79     0.0    False      0.62349   \n",
       "2023-07-03  fe5d18ae6650335830e4c1dbd9e6ddb9     2.0    False      0.62349   \n",
       "\n",
       "                week  mean_in_weekday_4_week  rolling_mean_7  rolling_max_7  \\\n",
       "date                                                                          \n",
       "2023-07-03 -0.984231                    0.00        0.001000            0.0   \n",
       "2023-07-03 -0.984231                    0.00        0.285714            1.0   \n",
       "2023-07-03 -0.984231                    0.75        1.142857            2.0   \n",
       "2023-07-03 -0.984231                    2.25        6.571429            8.0   \n",
       "2023-07-03 -0.984231                    1.25        1.428571            3.0   \n",
       "\n",
       "            rolling_min_7  ...  before_2days_holidays  \\\n",
       "date                       ...                          \n",
       "2023-07-03            0.0  ...                  False   \n",
       "2023-07-03            0.0  ...                  False   \n",
       "2023-07-03            0.0  ...                  False   \n",
       "2023-07-03            5.0  ...                  False   \n",
       "2023-07-03            0.0  ...                  False   \n",
       "\n",
       "                                  st_city_id  \\\n",
       "date                                           \n",
       "2023-07-03  885fe656777008c335ac96072a45be15   \n",
       "2023-07-03  885fe656777008c335ac96072a45be15   \n",
       "2023-07-03  885fe656777008c335ac96072a45be15   \n",
       "2023-07-03  885fe656777008c335ac96072a45be15   \n",
       "2023-07-03  885fe656777008c335ac96072a45be15   \n",
       "\n",
       "                            st_division_code  st_type_format_id  \\\n",
       "date                                                              \n",
       "2023-07-03  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2023-07-03  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2023-07-03  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2023-07-03  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "2023-07-03  296bd0cc6e735f9d7488ebc8fbc19130                  1   \n",
       "\n",
       "            st_type_loc_id  st_type_size_id    mean_seale  ratio_promo  \\\n",
       "date                                                                     \n",
       "2023-07-03               1               12  mean_seale_3     0.762251   \n",
       "2023-07-03               1               12  mean_seale_3     0.762251   \n",
       "2023-07-03               1               12  mean_seale_3     0.762251   \n",
       "2023-07-03               1               12  mean_seale_3     0.762251   \n",
       "2023-07-03               1               12  mean_seale_3     0.762251   \n",
       "\n",
       "            pr_uom_id  group_shop_cat  \n",
       "date                                   \n",
       "2023-07-03       True   group_2_cat_5  \n",
       "2023-07-03       True   group_2_cat_6  \n",
       "2023-07-03       True   group_2_cat_6  \n",
       "2023-07-03       True   group_2_cat_6  \n",
       "2023-07-03      False   group_2_cat_5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5d387",
   "metadata": {},
   "source": [
    "Сохраним получившиеся датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb943159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(PATH_TO_SAVE_TEST_DF)\n",
    "\n",
    "df_train_test.to_csv(PATH_TO_SAVE_TRAIN_TEST_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9475c",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44965ab9",
   "metadata": {},
   "source": [
    "В данном разделе была проведена прдобработка данных в ходе которой:\n",
    "1. Произведено преобразование кодов товаров в категории согласно EDA для дальнейшего обуечние моделей\n",
    "2. Созданы признаки для временного ряда (лаги, скользящие среднии, выделены дни недели, созданы флаги для выходных и праздничных дней, и ряд других признаков)\n",
    "3. Почищены данные от выбрасов.\n",
    "4. Проведено преобразование по информации о магазинах, удалены неактивные.\n",
    "5. Создан отдельный столбец для выбора конкретной модели для конкретного временного ряда.\n",
    "6. Созданы функции, позволяющие автоматизировать процес предообработки данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
